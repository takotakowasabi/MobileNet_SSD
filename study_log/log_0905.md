log:0905
==

# MNIST Training Tutorial

### Conv2D（[リファレンス](https://keras.io/ja/layers/convolutional/#conv2d)）
2次元の畳み込みレイヤーを指す

```python=
model.add(Conv2D(nb_filters, (nb_conv, nb_conv), padding='valid', input_shape=(img_rows, img_cols,1)))
```
モデルの第一層ではinput_shapeを指定しなくてはならない

input_shapeは整数のタプルで、画像の場合（高さ、幅、チャンネル数）

paddingは畳み込みを画像の端にも正しく行うために、画像を覆うように0を敷き詰める操作のこと。
validでpaddingを行い、sameで行わない

第一引数はフィルター数、第二引数は畳み込みのカーネルの大きさをとる

### Activation（[リファレンス](https://keras.io/ja/layers/core/#activation)）

```python=
model.add(Activation('relu'))
```

Activationは活性化関数（[リファレンス](https://keras.io/ja/activations/)）を指定できる

### MaxPooling2D（[リファレンス](https://keras.io/ja/layers/pooling/#maxpooling2d)）

引数pool_size（整数タプル）でMaxプーリングを行い、空間を圧縮するレイヤー
![](https://cdn-images-1.medium.com/max/1200/1*ReZNSf_Yr7Q1nqegGirsMQ@2x.png)

### Dropout （[リファレンス](https://keras.io/ja/layers/core/#dropout)）

第一引数のrate（0~1の浮動小数点数）の割合で入力ユニットをドロップする


---

optimizer='adadelta'
:	AdadeltaはAdaGradやRMSPropを改良したもので、新しい勾配情報を優先して計算し、かつ初期学習係数を必要としない


---


### Model::evaluate() （[リファレンス](https://keras.io/ja/models/model/#evaluate)）

テストモードで、モデルの損失値と評価値を返す

# TensorBoard

![](https://i.imgur.com/ArmSg2r.png)

![](https://i.imgur.com/zQ8T2i3.png)

valはtestとは別の汎化のためのデータ

ログファイルをサブディレクトリで分けると複数の試行を重畳してプロットできたり切り替えたりできる

KerasでTensorboardを使うためにはfitのcallbackでログを吐くように設定するだけ！
```python=
from keras.callbacks import TensorBoard

tb_cb = TensorBoard(log_dir="../LOG", histogram_freq=1)
cbks = [tb_cb]

model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_test, Y_test), callbacks=cbks)
```

dockerでtensorboardを走らせるには
```bash=
$ docker run --rm -it -d -v `pwd`/${log-pass}/logs -p 6006:6006 --name ${your-name}-tensorboard tensorboard
```

# Gitあれこれ

- tigを使う
- コミットはgit commit -vで差分を見るべし

    - remote のブランチ一覧を確認する

        > git remote -v

    - remote のブランチを追加する

        > git remote add ${remote-name} ${remote-url}

    - remote で登録したアドレスを変える

        > git remote set-url ${remote-name} ${remote-url}

    - remote に push する

        > git push ${remote-name} ${local-branch}

    - remote に別名で push する

        > git push ${remote-name} ${local-branch}:${remote-branch}

    - commit するとき差分をみる

        > git commit -v

    - v のエディタを変える

        > git config --global core.editor ${なんかすきなやつ}

- shell で branch の名前を確認する（push 事故を減らす）

    - at-intern-pc には bash, zsh, fish がある
bash の場合

        https://qiita.com/jun68ykt/items/d95010ad7dae2f802474


    - zsh の場合

        https://qiita.com/nishina555/items/f4f1ddc6ed7b0b296825

        https://github.com/robbyrussell/oh-my-zsh を入れていい感じのテーマを入れる


    - fish の場合

        https://qiita.com/mom0tomo/items/b593c0e98c1eea70a114
或いは fishermanでいい感じのテーマを入れる

# Dockerあれこれ

- -v オプションでホストの作業ディレクトリをマウントできる
- --rmで離れたら死ぬ
- -nameでコンテナに名前を付ける
- -itでコンテナ内でbashシェルが使える
- --runtime=でコンテナで使うランタイムを設定
- -eで環境変数を設定
- /bin/bashを最後に入れてbashを強制的に開く

# SSDについて

Object Detection
:	オブジェクト候補領域の検出とクラス分類を同時に行うタスクのこと
    SSDはこれを単一のネットーワークで行う

## Network Architecture

![](https://gitlab.fixstars.com/tech/EDEN/mobilenet-SSD/uploads/78f3e173b7131ee139113d00fd82b816/image.png)

- ベースとなるネットワークはVGG-16
- ネットワークが**multi-scale feature map**を持つ
    - 解像度によって検出するオブジェクトのスケールを分ける
    - 大きい解像度のものは小さいオブジェクトを担当し、小さい解像度のものは大きいオブジェクトを担当する


---


#### VGG16
![](https://cdn-ak.f.st-hatena.com/images/fotolife/a/aidiary/20170110/20170110200655.png)

```python=
from keras.applications.vgg16 import VGG16
model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)
```
