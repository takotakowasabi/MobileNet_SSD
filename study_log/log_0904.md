log:0904
===
<i class="fa fa-edit fa-fw"></i>2018/09/04 yusuke tomioka

# Kerasとは

Kerasは，Pythonで書かれた，TensorFlowまたはCNTK，Theano上で実行可能な高水準のニューラルネットワークライブラリで、以下の特徴を持つ
* 簡単で素早いプロトタイプの作成
* CNNとRNNをサポート
* CPUとGPU上でシームレスに動作


---

TensorFlow
:    Googleが開発する機械学習のためのソフトウェアライブラリ
    ディープラーニングに対応
    対応言語はC++,Python,Java,Go

CNN
:    後述

RNN
:    再起型ニューラルネットワーク
    自然言語処理で高い成果を上げる
    ![](https://camo.qiitausercontent.com/f95d56bf0c87e7170de6e3f05193e60f0bc619aa/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3130373331302f31393037616439392d306538392d636631342d306437372d6433386534656537643762372e6a706567)
    直前の計算に左右されずに、連続的な要素ごとに同じ作業を行わせることができる
    RNNは以前に計算された情報を覚えるための記憶力を持っている
   

---
 
# Kerasの基本

## Sequentialモデル

### Sequentialモデルの作成
```python=
from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential([
    Dense(32, input_shape=(784,)),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])

# or

model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
```
コンストラクタか.add()でレイヤーを作成

* Denseは二次元層
* Denseコンストラクタの第一引数はバッチ数
* 最初のレイヤーではimput_shapeをタプルで指定する
```python=
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
```
* 二次元層ならimput_dimだけ、三次元層ならimput_dimとimput_lengthでも代用可
```python=
model = Sequential()
model.add(Dense(32, input_dim=784))
```


---

relu
:	```python=
    #Example
    def relu(x) :
        return np.maximum(0, x)
    ```
    ![](https://i.imgur.com/n054MR7.png)

softmax
:	```python=
    #Example
    def softmax(a) :
        c = np.max(a)
        exp_a = np.exp(a - c)
        sum_exp_a = np.sum(exp_a)
        y = exp_a / sum_exp_a
        return y
    ```


---


### コンパイル

```python=
# マルチクラス分類問題の場合
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 2値分類問題の場合
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# 平均二乗誤差を最小化する回帰問題の場合
model.compile(optimizer='rmsprop',
              loss='mse')

# 独自定義の評価関数を定義
import keras.backend as K

def mean_pred(y_true, y_pred):
    return K.mean(y_pred)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy', mean_pred])
```
compileメソッドでどのような学習処理を行うかを設定する

引数は以下の３つ
1. 最適化アルゴリズム optimizer（[リファレンス](https://keras.io/ja/optimizers/)）
最適化手法の識別子もしくはoptimizerクラスのインスタンスを与える
optimizerのインスタンスであればパラメータを設定できる
```python=
sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='mean_squared_error', optimizer=sgd)
```

2. 損失関数 loss（[リファレンス](https://keras.io/ja/losses/)）
損失関数の識別子、もしくは自分で定義した関数を関数として与える

3. 評価関数リスト metrics（[リファレンス](https://keras.io/ja/metrics/)）
評価関数の識別子、もしくは自分で定義した関数を関数として与える
分類問題では精度としてmetrics=['accuracy']を指定しがち

### 学習

KerasモデルはNumpy配列として入力データとラベルデータから学習する

```python=
model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# ダミーデータ作成
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(10, size=(1000, 1))

# ラベルデータをカテゴリの1-hotベクトルにエンコードする
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)

# 各イテレーションのバッチサイズを32で学習を行なう
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
```
1つの入力から10クラスの分類を行なう（カテゴリ分類）

学習を行うには一般的にfit関数を用いる（[リファレンス](https://keras.io/ja/models/sequential/)）


---


epochs
:	整数で，モデルを訓練するエポック数． エポックは，提供されるxおよびyデータ全体の反復

verbose
:	0, 1または2．詳細表示モード．0とすると標準出力にログを出力しない． 1の場合はログをプログレスバーで標準出力，2の場合はエポックごとに1行のログを出力する

validation_data
:	各エポックの損失関数や評価関数で用いられるタプル


---


# MNIST Training Tutorial

```python=
# jupyter notebookでノート上にグラフを書くためのコード
%matplotlib inline
```

```python=
# mnistのデータを読み込む
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

```python=
# 読み込んだデータを画像として表示
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.axis('off')
    plt.title("class {}".format(y_train[i]))
```
subplotで3×3個のグラフを作成
imshowで画像を描画
axis('off')で軸とラベルを削除

```python=
# データの前処理

# データを行列に成型する
X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)

# データの型をfloat32に
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

# データの正規化
X_train /= 255
X_test /= 255
```

```python=
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3
```


---


convolutional filter
:	畳み込みを計算するフィルター
    ![](https://gitlab.fixstars.com/tech/behavioral-cloning/uploads/690bacfa2589994f729705a5e0b47fca/image.png)
    
max pooling
:	次元の削減のために領域内の最も大きい値を残す

# CNN

NewralNetworkに、独立したデータを渡すのではなく周囲のデータを畳み込みによって巻き込んだデータを用いて空間的な情報を残して処理する。