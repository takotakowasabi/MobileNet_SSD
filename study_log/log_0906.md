log:0906
==

# SSD

## Default Box

![](https://gitlab.fixstars.com/tech/EDEN/mobilenet-SSD/uploads/f3fcb20feadf45f364b88c1eeb91edcd/image.png)

ここ分かりやすかった→[リンク](https://avinton.com/blog/2018/03/single-shot-multibox-detector-explained1/)

DefaultBoxは画像内のオブジェクトの位置を予測するために置かれる8732個（SSD300の場合）の長方形で、その枠ごとに予測値を計算する

DefaultBoxの役割は自信と物体との距離（loc）と、その物体は何か（conf）を予測すること
→　それぞれのDefaultBoxに対してネットワークがオブジェクトクラスごとの予測値を出力する

背景以外に対して高い予測値を出した枠を選定し、そこから予測値が高いもの優先的に残す
ここで重なり度合いをIoU（Intersection over Union）を用いて判定する

![](https://i1.wp.com/avinton.com/wp-content/uploads/2018/03/Screen-Shot-2018-02-23-at-2.09.23-PM.png?w=651&ssl=1)

データとしては画像と正解短形、分類クラスを与える

解像度ごとに異なるアスペクト比のDefaultBoxが与えられる

## 損失関数

全体の目的誤差関数は位置特定誤差（loc）と確信度誤差（conf）の重み付き和となる

- total loss
![](https://camo.qiitausercontent.com/042ed30b5ba911e869234452f559320c01b7d36c/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343433302f33373737646439622d353164352d376465612d643463612d3137393738643535623438382e706e67)

- loc
![](https://camo.qiitausercontent.com/0852b4eb50bd1ca7891e4e48ea223b7193cd8943/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343433302f65303837383037662d363737362d646136372d326438382d3839393065353238326531642e706e67)

![](https://camo.qiitausercontent.com/7fafa17f51e978874afd7cee2d6f810ba229ba88/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343433302f63303866616466302d366366312d396234622d356330642d6330653962393034363966612e706e67)

- conf
![](https://camo.qiitausercontent.com/4561d7a21cf08f29058b4f8d484281775b4a5775/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343433302f32323838643433632d636364352d666438352d313332322d3235666334326166653132622e706e67)

## Hard-Negative Mining

各解像度の特徴マップごとにDefaultBoxを適用すると、DefaultBoxの数が膨大になり、アイテム候補領域でないNagativeBoxが多くなってしまう
→　よって正解短形（ground truth boxes）と重り率の低いものは学習させないようにし、PositiveBoxとNagativeBoxの比を、だいたい**1:3**にする

# SSD300 Tutorial

## pierluigiferrari/ssd_keras

### keras_ssd300（[GitHub](https://github.com/pierluigiferrari/ssd_keras/blob/master/models/keras_ssd300.py)）

#### コンストラクタ引数
1. **image_size**:整数タプル(height, width, channels)
2. **n_classes**:int、Positiveなクラスの数、Pascal VOCは20, MS COCOは80
3. **mode**:"training"（学習）、"inference"（推論）、"inference_fast"（高速推論）
4. **l2_regularization**:floatL2正則化に用いる正則化率、0に設定して無効にできる
5. **scales**:浮動小数点数リスト、各解像度の畳み込み層のスケーリングファクターを指定する
6. **aspect_ratios_per_layer**:floatのリストのリスト、各解像度の畳み込み層のアスペクト比を指定する
7. **two_boxes_for_ar1**:bool、アスペクト比1の2つのアンカーボックスを生成する
8. **steps**:整数リスト、各解像度ごとにアンカーボックスの中心点が画像上の空間グリッドに沿って垂直方向および水平方向にどれだけ離れているかを表します
9. **offsets**:floatリスト、steps引数で指定されたステップサイズとの割合で表される、画像の左上端から最も左上のアンカーボックスの中心点までの長さ
10. **clip_boxes**:bool、Trueにすると、画面境界内にとどまるようにアンカーボックスの座標をクリップする
11. **normalize_coords**:bool、モデルが相対座標を使い場合はTrue
12. **subtract_mean**:配列、３つの整数配列を入れればカラー画像のチャネルごとの平均正規化を実行できる
13. **swap_channels**:Falseか、入力画像チャンネルを入れ替えるべき望む順番を表す整数のリスト
14. **confidence_thresh**:Positiveクラスの信頼度の下限
15. **iou_threshold**:float、iou_thresholdより大きい重なり率を持つボックスはすべて、ローカルクラスの最大ボックスと予測クラスのセットから削除する
16. **top_k**:各バッチで保持される得点予測の数
17. **nms_max_output_size**:Non-Maximum Suppressionの後に残される予測の最大数

# 今日のdocker

- 以下のコードでbashからjupyterが起動できる
```
$ jupyter notebook --allow-root --ip=0.0.0.0
```